# Kaggle-optimized configuration
compute:
  device: "cuda"
  dtype: "float16"
  batch_size: 32
  cpu_offload: false  # Kaggle has good GPU memory

paths:
  cache_dir: "/kaggle/working/cache"
  output_dir: "/kaggle/working/results"
  hf_cache: "/kaggle/working/hf_cache"

analysis:
  num_samples: 10000
  layers: [0, 6, 11]  # Representative layers
  skip_sae: true  # For initial runs
  checkpoints: ["step1000-tokens4B"]  # Start with final checkpoint

# Model configuration inherited from src/config.py (single source of truth)
# To override: pass --model allenai/OLMo-2-0425-1B via CLI

